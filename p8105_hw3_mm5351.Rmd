---
title: "p8105_hw3_mm5351"
author: "Martha Mulugeta"
date: "10/6/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colur_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

***Problem 1***
```{r}
library(p8105.datasets)
data("instacart")
```

The instacart dataset contains `r nrow(instacart)` rows indicating the number of observations and `r ncol(instacart)` columns indicating the number of variables. Key variables include the numerical values for the order identifier (order_id), product ifentifier (product_id) and the  customer identifier (user_id). There are also identifiers specific to the types of products ordered such as the product name (product_name), the aisle it is from (aisle) and the department (department). 

For example, for the customer with the ID 112108, the products ordered include `r filter(instacart, user_id == 112108) %>% pull(product_name)`. These products came from the following aisles respectively: `r filter(instacart, user_id == 112108) %>% pull(aisle)`. 

```{r}
aisle_data = 
  instacart %>% 
  select(aisle) %>% 
  count(aisle) %>% 
  arrange(desc(n)) 
```

There are `r nrow(aisle_data)` aisles. The top five aisles that food is ordered from in descending order include fresh vegetables, fresh fruits, packaged vegetables, fruits,	yogurt, and packaged cheese. 

```{r}
aisle_plot =
  aisle_data %>% 
  arrange(aisle) %>% 
  filter(n > 10000)
  
##create plot  
aisle_plot %>% 
  ggplot(aes(x = n, y = aisle)) +
  geom_point(alpha = 0.5) +
    labs(
    title = "Number of Grocery Items Ordered in Each Aisle",
    x = "Number of Items Ordered",
    y = "Aisle",
    caption = "Data from Instacart")
```



```{r}
aisle_table1 =
  instacart %>% 
  select(aisle, product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>%
 mutate(product_rank = min_rank(desc(n))) %>% 
  filter(product_rank < 4) %>% 
  arrange(desc(n)) %>% 
  select(everything(), -product_rank)
```

```{r}
aisle_table2 = 
  instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(
    mean_hour = mean(order_hour_of_day)
  ) %>%  
  arrange(order_dow) %>%
  ##Format table  
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour,
  ) 
```



***Problem 2***
```{r}
library(p8105.datasets)
data("brfss_smart2010") 
```

```{r}
brfss_smart2010 =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  separate(col = locationdesc, sep = " -", into = c("state", "county")) %>%
  select(everything(), -locationabbr) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)) 
```  
  
In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
location2002_data = 
brfss_smart2010 %>% 
  select(year, state, county) %>%
  filter(year == 2002) %>% 
  group_by(state) %>% 
  count(state) %>% 
  filter(n >= 7)
```

In 2002, the states observed at 7 or more locations include `r pull(location2002_data, state)`.

```{r}
location2010_data = 
brfss_smart2010 %>% 
  select(year, state, county) %>%
  filter(year == 2010) %>% 
  group_by(state) %>% 
  count(state) %>% 
  filter(n >= 7)
```

In 2010, the states observed at 7 or more locations include `r pull(location2010_data, state)`.

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).
```{r}
excellent_data = 
brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  group_by(year, state) %>% 
  mutate(
    mean_data = mean(data_value)
  ) %>% 
  select(response, year, state, mean_data) %>% 
  drop_na()

##spaghetti plot
excellent_data %>% 
  ggplot(aes(x = year, y = mean_data, group = state, color = state)) +
  geom_line() + 
     labs(
    title = "Average Data Value Over Time Within Each State",
    x = "Year",
    y = "Average Data Value",
    caption = "Data from BRFSS")
```  

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
NY_data = 
  brfss_smart2010 %>% 
  select(year, state, county, response, data_value) %>% 
  mutate(state = as.factor(state)) %>% 
  filter(year %in% c(2006, 2010), state == "NY") 

NY_data %>% 
ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_grid(. ~year)
```


***Problem 3***
```{r}
accel_data = 
  read_csv("./Data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday = day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity"
    ) %>% 
  mutate(
    minute = as.numeric(minute),
    hour = minute %/% 60)
```

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate accross minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?  
```{r}
total_activity = 
accel_data %>% 
  group_by(week, day) %>% 
  summarize(
    total_activity = sum(activity)
  ) 
```

Accelerometer data allows the inspection activity over the course of the day. Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

```{r}
accel_data %>%
  group_by(week, day, hour) %>% 
  summarize(
    total_activity = sum(activity)
  ) %>% 
  
ggplot((aes(x = hour, y = total_activity, color = day))) +
  geom_line() +
    labs(
  title = "Accelerometer Activity Over the Course of the Day",
  x = "Hour of Day",
  y = "Activity",
  caption = "Data from Advanced Cardiac Care Center of Columbia University Medical Center")  
```








